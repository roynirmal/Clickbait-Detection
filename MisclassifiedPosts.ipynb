{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nroy0\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import dill\n",
    "dill.load_session(\"metodaysmall.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeMixedAccuracyLog2(posPatternClass, unigramsClass,  mixedClass, finalFeatures, finalFeaturesMSE, cross_val,c, cls):\n",
    "    \n",
    "    ##set up cross validation\n",
    "    cv_idx = KFold(n=len(varpd), n_folds=cross_val, shuffle=True, random_state=1)\n",
    "    \n",
    "    originalclass = []\n",
    "    predictedclass = []\n",
    "    \n",
    "    yclass = finalFeatures.iloc[:,-1]\n",
    "    posPatternMMSE = normalize(posPatternClass)\n",
    "    unigramsMMSE = normalize(unigramsClass)\n",
    "    mixedMMSE = normalize(mixedClass)\n",
    "    finalFeaturesNormMSE = normalize(finalFeatures)\n",
    "    \n",
    "    #only works with nd numpy arrays\n",
    "    \n",
    "    ycont = finalFeaturesMSE.truthMean.values\n",
    "    yp = posPatternClass.truthClass.values\n",
    "    yu = unigramsClass.truthClass.values\n",
    "    ym = mixedClass.truthClass.values\n",
    "    yf = finalFeatures.truthClass.values\n",
    "    \n",
    "    Xp = posPatternMMSE.as_matrix(columns = posPatternMMSE.columns)\n",
    "    Xu = unigramsMMSE.as_matrix(columns = unigramsMMSE.columns)\n",
    "    Xm = mixedMMSE.as_matrix(columns = mixedMMSE.columns)\n",
    "    Xf = finalFeaturesNormMSE.as_matrix(columns = finalFeaturesNormMSE.columns)\n",
    "    \n",
    "\n",
    "    Xp_new = SelectKBest(f_classif, k=\"all\").fit_transform(Xp, yp)\n",
    "    Xu_new = SelectKBest(f_classif, k=250).fit_transform(Xu, yu)\n",
    "    Xm_new = SelectKBest(f_classif, k=\"all\").fit_transform(Xm, ym)\n",
    "    Xf_new = SelectKBest(f_classif, k=\"all\").fit_transform(Xf, yf)\n",
    "    \n",
    "    \n",
    "    y_out = pd.DataFrame()\n",
    "#     scores = []\n",
    "    accM = []\n",
    "    accS = []\n",
    "#     scoresM = []\n",
    "    count = 0\n",
    "    \n",
    "    df = pd.DataFrame(np.random.randn(2459, 2))\n",
    "\n",
    "    msk = np.random.rand(len(df)) < 0.8\n",
    "\n",
    "\n",
    "    clrp = SVC(probability = True)\n",
    "    clru = LogisticRegressionCV()\n",
    "    clrm = SVC(probability = True)\n",
    "    clrf = LogisticRegressionCV()\n",
    "\n",
    "    clrp.fit(Xp_new[msk], yp[msk])\n",
    "    clru.fit(Xu_new[msk], yu[msk])\n",
    "    clrm.fit(Xm_new[msk], ym[msk])\n",
    "    clrf.fit(Xf_new[msk], yf[msk])\n",
    "\n",
    "    yp_pred = clrp.predict_proba(Xp_new[~msk])[:,1]\n",
    "    yp_pred_train = clrp.predict_proba(Xp_new[msk])[:,1]\n",
    "#             yp_pred = clrp.predict(Xp_new[val_idx])\n",
    "#             yp_pred_train = clrp.predict(Xp_new[train_idx])\n",
    "\n",
    "#             yu_pred = clru.predict(Xu_new[val_idx])\n",
    "#             yu_pred_train = clru.predict(Xu_new[train_idx])\n",
    "\n",
    "#             ym_pred = clrm.predict(Xm_new[val_idx])\n",
    "#             ym_pred_train = clrm.predict(Xm_new[train_idx])\n",
    "\n",
    "#             yf_pred = clrf.predict(Xf_new[val_idx])\n",
    "#             yf_pred_train = clrf.predict(Xf_new[train_idx])\n",
    "\n",
    "\n",
    "    yu_pred = clru.predict_proba(Xu_new[~msk])[:,1]\n",
    "    yu_pred_train = clru.predict_proba(Xu_new[msk])[:,1]\n",
    "\n",
    "    ym_pred = clrm.predict_proba(Xm_new[~msk])[:,1]\n",
    "    ym_pred_train = clrm.predict_proba(Xm_new[msk])[:,1]\n",
    "\n",
    "\n",
    "    yf_pred = clrf.predict_proba(Xf_new[~msk])[:,1]\n",
    "    yf_pred_train = clrf.predict_proba(Xf_new[msk])[:,1]\n",
    "\n",
    "#             y_out[\"c\"+str(count)]=y_pred\n",
    "#             count = count + 1\n",
    "\n",
    "    d1= {'p':yp_pred.tolist(), 'u':yu_pred.tolist(), 'm':ym_pred.tolist(), 'f':yf_pred.tolist(), 'y': yclass[~msk].tolist(), 'ycont': ycont[~msk].tolist()}\n",
    "    d2= {'p':yp_pred_train.tolist(), 'u':yu_pred_train.tolist(), 'm':ym_pred_train.tolist(), 'f':yf_pred_train.tolist(), 'y': yclass[msk].tolist(), 'ycont': ycont[msk].tolist()}\n",
    "    df1 = pd.DataFrame(d1)\n",
    "    df2 = pd.DataFrame(d2)\n",
    "\n",
    "    d= pd.concat([df1, df2])\n",
    "\n",
    "    X_train, y_train, ycont_train = df2[[\"p\", \"u\", \"m\", \"f\"]], df2[\"y\"], df2[\"ycont\"]\n",
    "    #test = d[~msk]\n",
    "    X_test, y_test, ycont_test = df1[[\"p\", \"u\", \"m\", \"f\"]], df1[\"y\"], df1[\"ycont\"]\n",
    "\n",
    "    if(cls == \"RF\"):\n",
    "        clf = RandomForestRegressor(max_depth=c, random_state=0) #i used random forest\n",
    "        #             prob = cl.predict_proba\n",
    "        clf.fit(X_train, ycont_train) # i changed this to work with regression\n",
    "        #score = clf.score(X_test, ycont_test) ## i removed this so that it worked with regression\n",
    "        prob = clf.predict(X_test)\n",
    "\n",
    "\n",
    "    elif(cls == \"SVC\"):\n",
    "        clf =  LinearSVR(C=c, loss='squared_epsilon_insensitive', dual=False, random_state=1)\n",
    "        #             prob = cl.predict_proba\n",
    "        clf.fit(X_train, ycont_train) # i changed this to work with regression\n",
    "        #score = clf.score(X_test, ycont_test) ## i removed this so that it worked with regression\n",
    "        prob = clf.predict(X_test)\n",
    "\n",
    "\n",
    "    elif(cls == \"Log\"):\n",
    "        clf = LogisticRegressionCV()\n",
    "        clf.fit(X_train, y_train)\n",
    "        prob = clf.predict_proba(X_test)[:,1]\n",
    "    elif(cls == \"Xg\"):\n",
    "        clf = GradientBoostingClassifier()\n",
    "        clf.fit(X_train, y_train)\n",
    "        prob = clf.predict_proba(X_test)[:,1] \n",
    "    elif(cls == \"XgBoost\"):\n",
    "        clf =  xgboost.XGBRegressor(n_estimators=100, learning_rate=0.08, gamma=0, subsample=0.75,\n",
    "                   colsample_bytree=1, max_depth=7)\n",
    "        #             prob = cl.predict_proba\n",
    "        clf.fit(X_train, ycont_train) # i changed this to work with regression\n",
    "        #score = clf.score(X_test, ycont_test) ## i removed this so that it worked with regression\n",
    "        prob = clf.predict(X_test)\n",
    "\n",
    "\n",
    "    lab_pred = prob.copy() # i added this to work with regression\n",
    "    lab_pred=np.where(lab_pred >= 0.5, 1,-1)\n",
    "    score = accuracy_score(lab_pred,y_test)\n",
    "    rmse = mean_squared_error(ycont_test, prob)\n",
    "#             accuracyM = scores.mean()\n",
    "#             accuracyS = scores.std()\n",
    "    accM.append(score)\n",
    "    accS.append(rmse)\n",
    "\n",
    "    originalclass.extend(y_test)\n",
    "    predictedclass.extend(lab_pred)\n",
    "#             y1 = { 'y': yclass[val_idx].tolist()}\n",
    "#             y2 = { 'y': yclass[train_idx].tolist()}\n",
    "#             yf1 = pd.DataFrame(y1)\n",
    "#             yf2 = pd.DataFrame(y2)\n",
    "#             ylab = pd.concat([y1, y2]) \n",
    "\n",
    "#             y_pred_final = pd.DataFrame(d)\n",
    "#             y_pred_final = pd.DataFrame(d)\n",
    "#             y_pred_final[\"mean\"] = y_pred_final.mean(axis=1)\n",
    "#             y_pred_final[\"median\"] = y_pred_final.iloc[:,0:4].median(axis=1)\n",
    "#             y_pred_final['class'] = np.where(y_pred_final['mean'] >= 0.5, 1,-1)\n",
    "# #             y_pred_final['class'] = np.where(y_pred_final['median'] >= 0.5, 1,-1)\n",
    "\n",
    "#             rmse = mean_squared_error(ycont[val_idx], y_pred_final[\"mean\"])\n",
    "#             scores.append(rmse)\n",
    "\n",
    "#             rmsemed = mean_squared_error(ycont[val_idx], y_pred_final[\"median\"])\n",
    "#             scoresM.append(rmsemed)\n",
    "\n",
    "#             accuracy = accuracy_score(yclass[val_idx], y_pred_final[\"class\"])\n",
    "#             acc.append(accuracy)\n",
    "\n",
    "#             rmse = mean_squared_error(y[val_idx], y_pred)\n",
    "#             scores.append(rmse)\n",
    "\n",
    "    mS = np.mean(accS)\n",
    "    sS = np.std(accS)\n",
    "    print(\"MSE: %0.3f (+/- %0.2f)\" % (mS, sS))\n",
    "\n",
    "#     return(d)\n",
    "    mA = np.mean(accM)\n",
    "    sA = np.std(accM)\n",
    "    print(\"Accuracy: %0.3f (+/- %0.2f)\" % (mA, sA))\n",
    "    \n",
    "    print(classification_report(originalclass, predictedclass)) \n",
    "    \n",
    "#     mMed = np.mean(scoresM)\n",
    "#     sMed = np.std(scoresM)\n",
    "#     print(\"MSEmedian: %0.3f (+/- %0.2f)\" % (mMed, sMed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "    originalclass = []\n",
    "    predictedclass = []\n",
    "    \n",
    "    yclass = finalFeatures.iloc[:,-1]\n",
    "    posPatternMMSE = normalize(posPatternClass)\n",
    "    unigramsMMSE = normalize(unigramsClass)\n",
    "    mixedMMSE = normalize(mixedClass)\n",
    "    finalFeaturesNormMSE = normalize(finalFeatures)\n",
    "    \n",
    "    #only works with nd numpy arrays\n",
    "    \n",
    "    ycont = finalFeaturesMSE.truthMean.values\n",
    "    yp = posPatternClass.truthClass.values\n",
    "    yu = unigramsClass.truthClass.values\n",
    "    ym = mixedClass.truthClass.values\n",
    "    yf = finalFeatures.truthClass.values\n",
    "    \n",
    "    Xp = posPatternMMSE.as_matrix(columns = posPatternMMSE.columns)\n",
    "    Xu = unigramsMMSE.as_matrix(columns = unigramsMMSE.columns)\n",
    "    Xm = mixedMMSE.as_matrix(columns = mixedMMSE.columns)\n",
    "    Xf = finalFeaturesNormMSE.as_matrix(columns = finalFeaturesNormMSE.columns)\n",
    "    \n",
    "\n",
    "    Xp_new = SelectKBest(f_classif, k=\"all\").fit_transform(Xp, yp)\n",
    "    Xu_new = SelectKBest(f_classif, k=250).fit_transform(Xu, yu)\n",
    "    Xm_new = SelectKBest(f_classif, k=\"all\").fit_transform(Xm, ym)\n",
    "    Xf_new = SelectKBest(f_classif, k=\"all\").fit_transform(Xf, yf)\n",
    "    \n",
    "    \n",
    "    y_out = pd.DataFrame()\n",
    "#     scores = []\n",
    "    accM = []\n",
    "    accS = []\n",
    "#     scoresM = []\n",
    "    count = 0\n",
    "    \n",
    "    df = pd.DataFrame(np.random.randn(2459, 2))\n",
    "\n",
    "    msk = np.random.rand(len(df)) < 0.9\n",
    "\n",
    "\n",
    "    clrp = SVC(probability = True)\n",
    "    clru = LogisticRegressionCV()\n",
    "    clrm = SVC(probability = True)\n",
    "    clrf = LogisticRegressionCV()\n",
    "\n",
    "    clrp.fit(Xp_new[msk], yp[msk])\n",
    "    clru.fit(Xu_new[msk], yu[msk])\n",
    "    clrm.fit(Xm_new[msk], ym[msk])\n",
    "    clrf.fit(Xf_new[msk], yf[msk])\n",
    "\n",
    "    yp_pred = clrp.predict_proba(Xp_new[~msk])[:,1]\n",
    "    yp_pred_train = clrp.predict_proba(Xp_new[msk])[:,1]\n",
    "#             yp_pred = clrp.predict(Xp_new[val_idx])\n",
    "#             yp_pred_train = clrp.predict(Xp_new[train_idx])\n",
    "\n",
    "#             yu_pred = clru.predict(Xu_new[val_idx])\n",
    "#             yu_pred_train = clru.predict(Xu_new[train_idx])\n",
    "\n",
    "#             ym_pred = clrm.predict(Xm_new[val_idx])\n",
    "#             ym_pred_train = clrm.predict(Xm_new[train_idx])\n",
    "\n",
    "#             yf_pred = clrf.predict(Xf_new[val_idx])\n",
    "#             yf_pred_train = clrf.predict(Xf_new[train_idx])\n",
    "\n",
    "\n",
    "    yu_pred = clru.predict_proba(Xu_new[~msk])[:,1]\n",
    "    yu_pred_train = clru.predict_proba(Xu_new[msk])[:,1]\n",
    "\n",
    "    ym_pred = clrm.predict_proba(Xm_new[~msk])[:,1]\n",
    "    ym_pred_train = clrm.predict_proba(Xm_new[msk])[:,1]\n",
    "\n",
    "\n",
    "    yf_pred = clrf.predict_proba(Xf_new[~msk])[:,1]\n",
    "    yf_pred_train = clrf.predict_proba(Xf_new[msk])[:,1]\n",
    "\n",
    "#             y_out[\"c\"+str(count)]=y_pred\n",
    "#             count = count + 1\n",
    "\n",
    "    d1= {'p':yp_pred.tolist(), 'u':yu_pred.tolist(), 'm':ym_pred.tolist(), 'f':yf_pred.tolist(), 'y': yclass[~msk].tolist(), 'ycont': ycont[~msk].tolist()}\n",
    "    d2= {'p':yp_pred_train.tolist(), 'u':yu_pred_train.tolist(), 'm':ym_pred_train.tolist(), 'f':yf_pred_train.tolist(), 'y': yclass[msk].tolist(), 'ycont': ycont[msk].tolist()}\n",
    "    df1 = pd.DataFrame(d1)\n",
    "    df2 = pd.DataFrame(d2)\n",
    "\n",
    "    d= pd.concat([df1, df2])\n",
    "\n",
    "    X_train, y_train, ycont_train = df2[[\"p\", \"u\", \"m\", \"f\"]], df2[\"y\"], df2[\"ycont\"]\n",
    "    #test = d[~msk]\n",
    "    X_test, y_test, ycont_test = df1[[\"p\", \"u\", \"m\", \"f\"]], df1[\"y\"], df1[\"ycont\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.74"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf =  LinearSVR(C=c, loss='squared_epsilon_insensitive', dual=False, random_state=1)\n",
    "        #             prob = cl.predict_proba\n",
    "clf.fit(X_train, ycont_train) # i changed this to work with regression\n",
    "#score = clf.score(X_test, ycont_test) ## i removed this so that it worked with regression\n",
    "prob = clf.predict(X_test)\n",
    "lab_pred = prob.copy() # i added this to work with regression\n",
    "lab_pred=np.where(lab_pred >= 0.5, 1,-1)\n",
    "score = accuracy_score(lab_pred,y_test)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  2,   7,   9,  17,  21,  26,  27,  28,  29,  30,  31,  38,  48,\n",
       "         53,  55,  56,  59,  65,  67,  71,  76,  85,  87,  88, 104, 108,\n",
       "        112, 127, 128, 130, 139, 140, 141, 142, 157, 158, 160, 162, 168,\n",
       "        183, 185, 186, 187, 194, 196, 200, 201, 206, 207, 214, 218, 219,\n",
       "        220, 222, 225, 226, 227, 228, 232, 233, 240, 241, 242, 244, 249],\n",
       "       dtype=int64),)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misclassified = np.where(y_test != lab_pred)\n",
    "misclassified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "mis = varpd[~msk]\n",
    "pp= mis.iloc[misclassified]\n",
    "pp = pd.merge(pp, Labels[[\"id\",\"truthClass\", \"truthMean\"]], on = \"id\")\n",
    "pp.to_csv(\"bar_miscl.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
