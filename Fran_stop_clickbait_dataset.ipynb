{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk as nl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading Data\n",
    "click_stopfile = 'C:/stop_clickbait/clickbait_data'\n",
    "noclick_stopfile = 'C:/stop_clickbait/non_clickbait_data'\n",
    "click_stopdata = pd.read_csv(click_stopfile, sep='\\n', header=None)\n",
    "noclick_stopdata = pd.read_csv(noclick_stopfile, sep='\\n', header=None)\n",
    "\n",
    "# Adding labels\n",
    "click_stopdata['truthClass'] = 'clickbait'\n",
    "noclick_stopdata['truthClass'] = 'no-clickbait'\n",
    "click_stopdata.columns = ['postText', 'truthClass']\n",
    "noclick_stopdata.columns = ['postText', 'truthClass']\n",
    "\n",
    "# Merge data\n",
    "stop_data = pd.concat([click_stopdata, noclick_stopdata])\n",
    "stop_data = stop_data.reset_index(drop=True)\n",
    "stop_data[\"id\"] = stop_data.index + 1\n",
    "stop_data = stop_data[['id', 'postText', 'truthClass']]\n",
    "# stop_data['postText'] = ('[' + stop_data['postText'] + ']')\n",
    "stop_data = stop_data.reset_index(drop=True)\n",
    "varpd = stop_data.copy()\n",
    "\n",
    "# Checking lengths\n",
    "# print(len(click_stopdata), len(noclick_stopdata), len(stop_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(varpd.index)\n",
    "varpd.iloc[0:4]\n",
    "varpd.to_json\n",
    "\n",
    "# with open('stopclickbait.json', 'w') as f:\n",
    "#     f.write(df.to_json(orient='records', lines=True))\n",
    "varpd.to_json('stopclickbait.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To JSON file\n",
    "varpd.to_json('stopclickbait.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# np.array([varfile['postText'] if varfile['id'] = 608310377143799808])\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "##varpd = pd.DataFrame.from_dict(varfile)\n",
    "\n",
    "##print(varpd.postText.iloc[0])\n",
    "\n",
    "##define functions to count number of characters and words. return -1 if there are no words/characters present\n",
    "def numChar(content):\n",
    "    if content is None:\n",
    "        return -1\n",
    "    elif not content:\n",
    "        return -1\n",
    "    elif type(content) is str:\n",
    "        return len(content)\n",
    "    else:\n",
    "        \n",
    "        for i in content :\n",
    "            return len(i)\n",
    "        \n",
    "    \n",
    "def numWords(content):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    if content is None:\n",
    "        return -1\n",
    "    elif not content:\n",
    "        return -1\n",
    "    elif type(content) is str:\n",
    "        content_no_punc = tokenizer.tokenize(content)\n",
    "        if(len(content_no_punc)==0):\n",
    "            return -1\n",
    "        else:\n",
    "            return len(content_no_punc)\n",
    "    else:\n",
    "        content_no_punc = tokenizer.tokenize(content[0])\n",
    "        if(len(content_no_punc)==0):\n",
    "            return -1\n",
    "        else:\n",
    "            return len(content_no_punc)\n",
    "        \n",
    "##similar functions like above. but return 0 instead of -1. we need it for counting difference in characters/words\n",
    "        \n",
    "def numChar0(content):\n",
    "    if content is None:\n",
    "        return 0\n",
    "    elif not content:\n",
    "        return 0\n",
    "    elif type(content) is str:\n",
    "        return len(content)\n",
    "    else:\n",
    "        \n",
    "        for i in content :\n",
    "            return len(i)\n",
    "        \n",
    "    \n",
    "def numWords0(content):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    if content is None:\n",
    "        return 0\n",
    "    elif not content:\n",
    "        return 0\n",
    "    elif type(content) is str:\n",
    "        content_no_punc = tokenizer.tokenize(content)\n",
    "        return len(content_no_punc)\n",
    "    else:\n",
    "        content_no_punc = tokenizer.tokenize(content[0])\n",
    "        return len(content_no_punc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Feature: Number of Characters\n",
    "features = varpd[['id']].copy()\n",
    "\n",
    "postlen = pd.DataFrame(columns = [\"postlen\"])\n",
    "\n",
    "for ind in range(len(varpd.index)):\n",
    "    \n",
    "    postlen = postlen.append(pd.DataFrame([numChar(varpd.iloc[ind]['postText'])], columns = [\"postlen\"] ), ignore_index = True)\n",
    "    \n",
    "features  =  pd.concat([features, postlen], axis=1)\n",
    "#features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Dataframe used for counting features which involves measuring difference of words/character(notice the functions used)\n",
    "\n",
    "features0 = varpd[['id']].copy()\n",
    "\n",
    "\n",
    "postlen0 = pd.DataFrame(columns = [\"postlen\"])\n",
    "\n",
    "\n",
    "for ind in range(len(varpd.index)):\n",
    "    \n",
    "    postlen0 = postlen0.append(pd.DataFrame([numChar0(varpd.iloc[ind]['postText'])], columns = [\"postlen\"] ), ignore_index = True)\n",
    "\n",
    "    \n",
    "features0  =  pd.concat([features0, postlen0], axis=1)\n",
    "\n",
    "\n",
    "features20 = varpd[['id']].copy()\n",
    "postword0 = pd.DataFrame(columns = [\"postword\"])\n",
    "\n",
    "\n",
    "for ind in range(len(varpd.index)):\n",
    "    \n",
    "    postword0 = postword0.append(pd.DataFrame([numWords0(varpd.iloc[ind]['postText'])], columns = [\"postword\"] ), ignore_index = True)\n",
    "  \n",
    "    \n",
    "    \n",
    "features20  =  pd.concat([features20, postword0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>postword</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31970</th>\n",
       "      <td>15972</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31971</th>\n",
       "      <td>15973</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31972</th>\n",
       "      <td>15974</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31973</th>\n",
       "      <td>15975</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31974</th>\n",
       "      <td>15976</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31975</th>\n",
       "      <td>15977</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31976</th>\n",
       "      <td>15978</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31977</th>\n",
       "      <td>15979</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31978</th>\n",
       "      <td>15980</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31979</th>\n",
       "      <td>15981</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31980</th>\n",
       "      <td>15982</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31981</th>\n",
       "      <td>15983</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31982</th>\n",
       "      <td>15984</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31983</th>\n",
       "      <td>15985</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31984</th>\n",
       "      <td>15986</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31985</th>\n",
       "      <td>15987</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31986</th>\n",
       "      <td>15988</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31987</th>\n",
       "      <td>15989</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31988</th>\n",
       "      <td>15990</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31989</th>\n",
       "      <td>15991</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31990</th>\n",
       "      <td>15992</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31991</th>\n",
       "      <td>15993</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31992</th>\n",
       "      <td>15994</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31993</th>\n",
       "      <td>15995</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31994</th>\n",
       "      <td>15996</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31995</th>\n",
       "      <td>15997</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31996</th>\n",
       "      <td>15998</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31997</th>\n",
       "      <td>15999</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31998</th>\n",
       "      <td>16000</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31999</th>\n",
       "      <td>16001</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id postword\n",
       "0          1        4\n",
       "1          2        9\n",
       "2          3       14\n",
       "3          4       12\n",
       "4          5       18\n",
       "5          6       13\n",
       "6          7        9\n",
       "7          8        6\n",
       "8          9       11\n",
       "9         10       19\n",
       "10        11        7\n",
       "11        12       11\n",
       "12        13        9\n",
       "13        14        5\n",
       "14        15        9\n",
       "15        16       10\n",
       "16        17        7\n",
       "17        18       17\n",
       "18        19        8\n",
       "19        20        8\n",
       "20        21        8\n",
       "21        22       11\n",
       "22        23        7\n",
       "23        24        4\n",
       "24        25        8\n",
       "25        26        8\n",
       "26        27       16\n",
       "27        28        9\n",
       "28        29        8\n",
       "29        30       13\n",
       "...      ...      ...\n",
       "31970  15972       12\n",
       "31971  15973       10\n",
       "31972  15974        4\n",
       "31973  15975        8\n",
       "31974  15976        6\n",
       "31975  15977        7\n",
       "31976  15978        8\n",
       "31977  15979        7\n",
       "31978  15980        9\n",
       "31979  15981        9\n",
       "31980  15982        8\n",
       "31981  15983        8\n",
       "31982  15984        9\n",
       "31983  15985       11\n",
       "31984  15986        6\n",
       "31985  15987        6\n",
       "31986  15988        7\n",
       "31987  15989       11\n",
       "31988  15990        8\n",
       "31989  15991        8\n",
       "31990  15992        7\n",
       "31991  15993        7\n",
       "31992  15994        7\n",
       "31993  15995        7\n",
       "31994  15996       14\n",
       "31995  15997       10\n",
       "31996  15998        9\n",
       "31997  15999       12\n",
       "31998  16000        9\n",
       "31999  16001        9\n",
       "\n",
       "[32000 rows x 2 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Feature: Number of Words\n",
    "features2 = varpd[['id']].copy()\n",
    "postword = pd.DataFrame(columns = [\"postword\"])\n",
    "\n",
    "for ind in range(len(varpd.index)):\n",
    "    \n",
    "    postword = postword.append(pd.DataFrame([numWords(varpd.iloc[ind]['postText'])], columns = [\"postword\"] ), ignore_index = True) \n",
    "    \n",
    "features2  =  pd.concat([features2, postword], axis=1)\n",
    "features2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "single positional indexer is out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-57-ae923d352a79>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mtemp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures20\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mfeatures20\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"wordDiff\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0mfeatures3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeatures3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtemp\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1323\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mKeyError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1324\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1325\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1326\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1327\u001b[0m             \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m   1660\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1661\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1662\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_has_valid_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1663\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1664\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_lowerdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_has_valid_tuple\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    187\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mIndexingError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Too many indexers'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 189\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_has_valid_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    190\u001b[0m                 raise ValueError(\"Location based indexing can only have [%s] \"\n\u001b[0;32m    191\u001b[0m                                  \"types\" % self._valid_types)\n",
      "\u001b[1;32mE:\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_has_valid_type\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1595\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1596\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1597\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_valid_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1598\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mis_list_like_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1599\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_valid_list_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_is_valid_integer\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1636\u001b[0m         \u001b[0ml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1637\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1638\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"single positional indexer is out-of-bounds\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1639\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1640\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: single positional indexer is out-of-bounds"
     ]
    }
   ],
   "source": [
    "#Feature: Difference in Number of words\n",
    "features3 = varpd[['id']].copy()\n",
    "\n",
    "for i in range(1,6):\n",
    "    for j in range(i+1,7):\n",
    "        temp = pd.DataFrame(abs(features20.iloc[:,i]-features20.iloc[:,j]), columns = [\"wordDiff\"+str(i)+str(j)])\n",
    "        features3 = pd.concat([features3, temp], axis = 1)\n",
    "\n",
    "features3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Feature: Difference in Number of Characters\n",
    "features4 = varpd[['id']].copy()\n",
    "\n",
    "for i in range(1,6):\n",
    "    for j in range(i+1,7):\n",
    "        temp = pd.DataFrame(abs(features0.iloc[:,i]-features0.iloc[:,j]), columns = [\"charDiff\"+str(i)+str(j)])\n",
    "        features4 = pd.concat([features4, temp], axis = 1)\n",
    "\n",
    "features4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Feature: Ratio of number of words\n",
    "features5 = varpd[['id']].copy()\n",
    "\n",
    "for i in range(1,6):\n",
    "    for j in range(i+1,7):\n",
    "        temp = pd.DataFrame(abs(features2.iloc[:,i]/features2.iloc[:,j]), columns = [\"wordRatio\"+str(i)+str(j)])\n",
    "        temp.loc[features2.iloc[:,i] == -1, \"wordRatio\"+str(i)+str(j)] = -1\n",
    "        temp.loc[features2.iloc[:,j] == -1, \"wordRatio\"+str(i)+str(j)] = -1\n",
    "        features5 = pd.concat([features5, temp], axis = 1)\n",
    "\n",
    "features5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Feature: Ratio of number of Characters\n",
    "features6 = varpd[['id']].copy()\n",
    "\n",
    "for i in range(1,6):\n",
    "    for j in range(i+1,7):\n",
    "        temp = pd.DataFrame(abs(features.iloc[:,i]/features.iloc[:,j]), columns = [\"charRatio\"+str(i)+str(j)])\n",
    "        temp.loc[features.iloc[:,i] == -1, \"charRatio\"+str(i)+str(j)] = -1\n",
    "        temp.loc[features.iloc[:,j] == -1, \"charRatio\"+str(i)+str(j)] = -1\n",
    "        features6 = pd.concat([features6, temp], axis = 1)\n",
    "\n",
    "features6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function: Common words Between Article Keywords and Others\n",
    "\n",
    "def commonWords(keyword, content):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    keyword_no_punc = tokenizer.tokenize(keyword)\n",
    "    if(len(keyword_no_punc)==0):\n",
    "        return 0\n",
    "    elif (content is None):\n",
    "        return 0\n",
    "    elif (not content):\n",
    "        return 0\n",
    "    elif type(content) is str:\n",
    "        content_no_punc = tokenizer.tokenize(content)\n",
    "        return len(list(set(keyword_no_punc) & set(content_no_punc)))\n",
    "    else:\n",
    "        content_no_punc = tokenizer.tokenize(content[0])\n",
    "        return len(list(set(keyword_no_punc) & set(content_no_punc)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'commonWords' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-66-f745c3c8d54b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mind\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvarpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mcommonpost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcommonpost\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcommonWords\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvarpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mind\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'targetKeywords'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvarpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mind\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'postText'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"commonpost\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'commonWords' is not defined"
     ]
    }
   ],
   "source": [
    "#Feature: Common words Between Article Keywords and Others\n",
    "\n",
    "\n",
    "features7 = varpd[['id']].copy()\n",
    "\n",
    "commonpost = pd.DataFrame(columns = [\"commonpost\"])\n",
    "\n",
    "for ind in range(len(varpd.index)):\n",
    "    \n",
    "    commonpost = commonpost.append(pd.DataFrame([commonWords(varpd.iloc[ind]['targetKeywords'], varpd.iloc[ind]['postText'])], columns = [\"commonpost\"] ), ignore_index = True)\n",
    "    \n",
    "    \n",
    "features7  =  pd.concat([features7, commonpost], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Feature: Presence of an image\n",
    "\n",
    "features8 = varpd[['id']].copy()\n",
    "imagePresent = pd.DataFrame(1, index = np.arange(2459), columns = [\"imagePresent\"])\n",
    "\n",
    "for i in range(len(varpd.index)):\n",
    "    if not varfile.iloc[i,1]:\n",
    "        imagePresent.loc[i, \"imagePresent\"] = 0\n",
    "#np.where( varfile['postMedia'] )\n",
    "#np.arange(2459)\n",
    "#varfile.iloc[:,1]\n",
    "features8  =  pd.concat([features8, imagePresent], axis=1)\n",
    "features8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function: Number of formal words\n",
    "\n",
    "def formalWords(content):\n",
    "    c=0\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    if content is None:\n",
    "        return 0\n",
    "    elif not content:\n",
    "        return 0\n",
    "    elif type(content) is str:\n",
    "        content_no_punc = tokenizer.tokenize(content)\n",
    "        for word in [x.lower() for x in content_no_punc]:\n",
    "            if word in words.words():\n",
    "                c=c+1\n",
    "        return c\n",
    "    else:\n",
    "        content_no_punc = tokenizer.tokenize(content[0])\n",
    "        for word in [x.lower() for x in content_no_punc]:\n",
    "            if word in words.words():\n",
    "                c=c+1\n",
    "        return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Feature: Number of Formal Words\n",
    "features9 = varpd[['id']].copy()\n",
    "postform = pd.DataFrame(columns = [\"postform\"])\n",
    "\n",
    "\n",
    "for ind in range(len(varpd.index)):\n",
    "    \n",
    "    postform = postform.append(pd.DataFrame([formalWords(varpd.iloc[ind]['postText'])], columns = [\"postform\"] ), ignore_index = True)\n",
    "\n",
    "    if(ind%10 == 0): \n",
    "        print(ind)\n",
    "    \n",
    "    \n",
    "features9  =  pd.concat([features9, postform], axis=1)\n",
    "features9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Feature: Ratio of number of formal words to total number of words\n",
    "def formalRatio(formal, total):\n",
    "    if (total==-1):\n",
    "        return -1\n",
    "    else:\n",
    "        return abs(formal/total)\n",
    "\n",
    "\n",
    "features10 = varpd[['id']].copy()\n",
    "postratio = pd.DataFrame(columns = [\"postratio\"])\n",
    "\n",
    "\n",
    "for ind in range(len(varpd.index)):\n",
    "    \n",
    "    postratio = postratio.append(pd.DataFrame([formalRatio(features9.iloc[ind]['postform'], features2.iloc[ind]['postword'] )], columns = [\"postratio\"] ), ignore_index = True)\n",
    "\n",
    "    \n",
    "features10  =  pd.concat([features10, postratio], axis=1)\n",
    "features10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function: POS tags, personal pronouns\n",
    "\n",
    "# posFreq: returns a vector with the frequency of every POS tag in a given content\n",
    "def posFreq(content):\n",
    "    posTags = pd.DataFrame(nl.pos_tag(nl.word_tokenize(str(content)[2:-2])))\n",
    "    posFrequencies = posTags[1].value_counts()\n",
    "    totalWords = posFrequencies.sum()\n",
    "    posFreqNormlized = posFrequencies/totalWords\n",
    "    return posFreqNormlized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Feature: POS tags, personal pronouns\n",
    "postTitleTags = varpd['postText'].apply(posFreq)\n",
    "# postTitleTags = varfile['postText'].apply(posFreq)\n",
    "postTitleTags.fillna(0, inplace=True)\n",
    "# artTitleTags = varfile['targetTitle'].apply(posFreq)\n",
    "postTitlePRP = pd.DataFrame(columns = [\"postPRP\"])\n",
    "postTitlePRPS = pd.DataFrame(columns = [\"postPRPS\"])\n",
    "\n",
    "features11 = pd.concat([varpd[['id']].copy(), postTitleTags['PRP'], postTitleTags['PRP$']], ignore_index=True, axis=1)\n",
    "features11.columns = ['id', 'postTitlePRP', 'postTitlePRPS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalFeatures = pd.merge(features, features2,  on='id')\n",
    "# finalFeatures = pd.merge(finalFeatures, features3,  on='id')\n",
    "# finalFeatures = pd.merge(finalFeatures, features4,  on='id')\n",
    "# finalFeatures = pd.merge(finalFeatures, features5,  on='id')\n",
    "# finalFeatures = pd.merge(finalFeatures, features6,  on='id')\n",
    "# finalFeatures = pd.merge(finalFeatures, features7,  on='id')\n",
    "#finalFeatures = pd.merge(finalFeatures, features8,  on='id')\n",
    "finalFeatures = pd.merge(finalFeatures, features11,  on='id')\n",
    "\n",
    "len(finalFeatures.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# finalFeatures = pd.merge(finalFeatures, features9,  on='id')\n",
    "# finalFeatures = pd.merge(finalFeatures, features10,  on='id')\n",
    "\n",
    "numFeatures = len(finalFeatures.keys())\n",
    "\n",
    "featNorm = finalFeatures.copy()\n",
    "for  k in range(1,numFeatures):\n",
    "    m = np.mean(finalFeatures.iloc[:,k])\n",
    "    s = np.std(finalFeatures.iloc[:,k])\n",
    "    featNorm.iloc[:,k] = (finalFeatures.iloc[:,k]-m)/s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "featNorm = finalFeatures.copy()\n",
    "for k in range(1,numFeatures ):\n",
    "    m = np.mean(finalFeatures.iloc[:,k])\n",
    "    s = np.std(finalFeatures.iloc[:,k])\n",
    "    featNorm.iloc[:,k] = (finalFeatures.iloc[:,k]-m)/s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "featNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>truthClass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31970</th>\n",
       "      <td>15972</td>\n",
       "      <td>no-clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31971</th>\n",
       "      <td>15973</td>\n",
       "      <td>no-clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31972</th>\n",
       "      <td>15974</td>\n",
       "      <td>no-clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31973</th>\n",
       "      <td>15975</td>\n",
       "      <td>no-clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31974</th>\n",
       "      <td>15976</td>\n",
       "      <td>no-clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31975</th>\n",
       "      <td>15977</td>\n",
       "      <td>no-clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31976</th>\n",
       "      <td>15978</td>\n",
       "      <td>no-clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31977</th>\n",
       "      <td>15979</td>\n",
       "      <td>no-clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31978</th>\n",
       "      <td>15980</td>\n",
       "      <td>no-clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31979</th>\n",
       "      <td>15981</td>\n",
       "      <td>no-clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31980</th>\n",
       "      <td>15982</td>\n",
       "      <td>no-clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31981</th>\n",
       "      <td>15983</td>\n",
       "      <td>no-clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31982</th>\n",
       "      <td>15984</td>\n",
       "      <td>no-clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31983</th>\n",
       "      <td>15985</td>\n",
       "      <td>no-clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31984</th>\n",
       "      <td>15986</td>\n",
       "      <td>no-clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31985</th>\n",
       "      <td>15987</td>\n",
       "      <td>no-clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31986</th>\n",
       "      <td>15988</td>\n",
       "      <td>no-clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31987</th>\n",
       "      <td>15989</td>\n",
       "      <td>no-clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31988</th>\n",
       "      <td>15990</td>\n",
       "      <td>no-clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31989</th>\n",
       "      <td>15991</td>\n",
       "      <td>no-clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31990</th>\n",
       "      <td>15992</td>\n",
       "      <td>no-clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31991</th>\n",
       "      <td>15993</td>\n",
       "      <td>no-clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31992</th>\n",
       "      <td>15994</td>\n",
       "      <td>no-clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31993</th>\n",
       "      <td>15995</td>\n",
       "      <td>no-clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31994</th>\n",
       "      <td>15996</td>\n",
       "      <td>no-clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31995</th>\n",
       "      <td>15997</td>\n",
       "      <td>no-clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31996</th>\n",
       "      <td>15998</td>\n",
       "      <td>no-clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31997</th>\n",
       "      <td>15999</td>\n",
       "      <td>no-clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31998</th>\n",
       "      <td>16000</td>\n",
       "      <td>no-clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31999</th>\n",
       "      <td>16001</td>\n",
       "      <td>no-clickbait</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id    truthClass\n",
       "0          1     clickbait\n",
       "1          2     clickbait\n",
       "2          3     clickbait\n",
       "3          4     clickbait\n",
       "4          5     clickbait\n",
       "5          6     clickbait\n",
       "6          7     clickbait\n",
       "7          8     clickbait\n",
       "8          9     clickbait\n",
       "9         10     clickbait\n",
       "10        11     clickbait\n",
       "11        12     clickbait\n",
       "12        13     clickbait\n",
       "13        14     clickbait\n",
       "14        15     clickbait\n",
       "15        16     clickbait\n",
       "16        17     clickbait\n",
       "17        18     clickbait\n",
       "18        19     clickbait\n",
       "19        20     clickbait\n",
       "20        21     clickbait\n",
       "21        22     clickbait\n",
       "22        23     clickbait\n",
       "23        24     clickbait\n",
       "24        25     clickbait\n",
       "25        26     clickbait\n",
       "26        27     clickbait\n",
       "27        28     clickbait\n",
       "28        29     clickbait\n",
       "29        30     clickbait\n",
       "...      ...           ...\n",
       "31970  15972  no-clickbait\n",
       "31971  15973  no-clickbait\n",
       "31972  15974  no-clickbait\n",
       "31973  15975  no-clickbait\n",
       "31974  15976  no-clickbait\n",
       "31975  15977  no-clickbait\n",
       "31976  15978  no-clickbait\n",
       "31977  15979  no-clickbait\n",
       "31978  15980  no-clickbait\n",
       "31979  15981  no-clickbait\n",
       "31980  15982  no-clickbait\n",
       "31981  15983  no-clickbait\n",
       "31982  15984  no-clickbait\n",
       "31983  15985  no-clickbait\n",
       "31984  15986  no-clickbait\n",
       "31985  15987  no-clickbait\n",
       "31986  15988  no-clickbait\n",
       "31987  15989  no-clickbait\n",
       "31988  15990  no-clickbait\n",
       "31989  15991  no-clickbait\n",
       "31990  15992  no-clickbait\n",
       "31991  15993  no-clickbait\n",
       "31992  15994  no-clickbait\n",
       "31993  15995  no-clickbait\n",
       "31994  15996  no-clickbait\n",
       "31995  15997  no-clickbait\n",
       "31996  15998  no-clickbait\n",
       "31997  15999  no-clickbait\n",
       "31998  16000  no-clickbait\n",
       "31999  16001  no-clickbait\n",
       "\n",
       "[32000 rows x 2 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Labels = varpd[['id','truthClass']].copy()\n",
    "Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Labels.loc[Labels.iloc[:,1] == \"no-clickbait\", \"truthClass\"] = -1\n",
    "Labels.loc[Labels.iloc[:,1] == \"clickbait\", \"truthClass\"] = 1\n",
    "featwithLab = pd.merge(featNorm, Labels[[\"id\",\"truthClass\"]], on = \"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "featwithLab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.500 (+/- 0.000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "numFeatures\n",
    "# X_train, X_test, y_train, y_test = train_test_split(featwithLab.iloc[:,1:91], featwithLab.iloc[:,91], test_size=0.4, random_state=0)\n",
    "\n",
    "clf = SVC()\n",
    "scores = cross_val_score(clf, list(featwithLab.iloc[:,1:numFeatures].values), list(featwithLab.iloc[:,numFeatures].values), cv=10)\n",
    "# clf.fit(X_train, y_train)\n",
    "# clf.score(X_test, y_test)\n",
    "print(\"Accuracy: %0.3f (+/- %0.3f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(featwithLab.iloc[:,1:91], featwithLab.iloc[:,91], test_size=0.4, random_state=0)\n",
    "\n",
    "clf = LogisticRegressionCV()\n",
    "scores = cross_val_score(clf, featwithLab.iloc[:,1:81], featwithLab.iloc[:,81], cv=10)\n",
    "# clf.fit(X_train, y_train)\n",
    "# clf.score(X_test, y_test)\n",
    "print(\"Accuracy: %0.3f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(featwithLab.iloc[:,1:91], featwithLab.iloc[:,91], test_size=0.4, random_state=0)\n",
    "\n",
    "clf = GradientBoostingClassifier()\n",
    "scores = cross_val_score(clf, featwithLab.iloc[:,1:81], featwithLab.iloc[:,81], cv=10)\n",
    "# clf.fit(X_train, y_train)\n",
    "# clf.score(X_test, y_test)\n",
    "print(\"Accuracy: %0.3f (+/- %0.3f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(featwithLab.iloc[:,1:91], featwithLab.iloc[:,91], test_size=0.4, random_state=0)\n",
    "\n",
    "clf = RandomForestClassifier(criterion = 'entropy')\n",
    "scores = cross_val_score(clf, featwithLab.iloc[:,1:81], featwithLab.iloc[:,81], cv=20)\n",
    "# clf.fit(X_train, y_train)\n",
    "# clf.score(X_test, y_test)\n",
    "print(\"Accuracy: %0.3f (+/- %0.3f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "import operator\n",
    "\n",
    "\n",
    "\n",
    "info_gain = dict(zip(list(featwithLab.iloc[:,1:numFeatures]), mutual_info_classif(featwithLab.iloc[:,1:numFeatures].values.tolist(), featwithLab.iloc[:,numFeatures].values.tolist())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c = 0\n",
    "for w in sorted(info_gain, key = info_gain.get, reverse = True):\n",
    "    c=c+1\n",
    "    print (w, info_gain[w])\n",
    "    if (c==20):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mutual_info_classif(featwithLab.iloc[:,1:numFeatures].values.tolist(), featwithLab.iloc[:,numFeatures].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import dill\n",
    "#dill.load_session('notebook_env.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import dill\n",
    "dill.dump_session('notebook_env.db')\n",
    "# dill. _session('notebook_env.db')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
